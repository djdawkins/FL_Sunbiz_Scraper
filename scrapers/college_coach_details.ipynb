{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import scrapelib\n",
    "from bs4 import BeautifulSoup\n",
    "import settings\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = scrapelib.Scraper(retry_attempts=3, requests_per_minute=settings.REQUESTS_PER_MINUTE)\n",
    "page_num = 1\n",
    "\n",
    "coach_url_df = pd.read_csv('all_coaches.csv')\n",
    "# coach_url_df = coach_url_df[coach_url_df[\"Head coach\"] == \"Kalani Sitake\"]\n",
    "\n",
    "hc_df = coach_url_df.copy()\n",
    "\n",
    "df_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Tom_Herman'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_df[\"coach_url\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deion Sanders\n",
      "James Thomas Jr.\n"
     ]
    }
   ],
   "source": [
    "for i in hc_df.index:\n",
    "# for i in hc_coach_urls:\n",
    "# for i in range(3, 4):\n",
    "\n",
    "    page = s.get(\"https://en.wikipedia.org\" + hc_df[\"coach_url\"][i])\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    page_id = soup.find(\"a\", {\"class\": \"wbc-editpage\"}, href=True)['href']\n",
    "    page_id = re.search(r'Q\\d*', page_id).group()\n",
    "\n",
    "    table_elm = soup.find('table', {\"class\": \"infobox vcard\"})\n",
    "    \n",
    "    if not table_elm:\n",
    "        table_elm = soup.find('table', {\"class\": \"infobox biography vcard\"})\n",
    "        print(hc_df[\"coach\"][i])\n",
    "\n",
    "    tr_list = table_elm.find_all(\"tr\")\n",
    "\n",
    "    tuple_list = []\n",
    "    i_header_text = \"\"\n",
    "    for tr in tr_list:\n",
    "        \n",
    "        i_image = tr.find(\"td\", {\"class\": \"infobox-image\"})\n",
    "        if i_image:\n",
    "            continue\n",
    "            \n",
    "        i_header = tr.find(\"th\", {\"class\": \"infobox-header\"})\n",
    "\n",
    "        if i_header:\n",
    "            i_header_text = i_header.get_text()\n",
    "            continue\n",
    "        \n",
    "        i_label = tr.find(\"th\", {\"class\": \"infobox-label\"})\n",
    "        i_data = tr.find(\"td\", {\"class\": \"infobox-data\"})\n",
    "\n",
    "        if i_label:\n",
    "\n",
    "            i_label_text = i_label.get_text()\n",
    "            i_data_text = i_data.get_text()\n",
    "            school_href = \"\"\n",
    "            position_href = \"\"\n",
    "\n",
    "            school_a = i_data.find_all(\"a\", href=True)\n",
    "            \n",
    "            school_href = school_a[0][\"href\"] if len(school_a) == 1 else \"\"\n",
    "            school_href = school_a[0][\"href\"] if len(school_a) == 2 else \"\"\n",
    "            \n",
    "            # school_title = school_a[0][\"title\"] if len(school_a) == 2 else \"\"\n",
    "            school_title = school_a[0].get(\"title\") if len(school_a) == 2 else \"\"\n",
    "\n",
    "            idx = 0\n",
    "            title_list = []\n",
    "            link_list = []\n",
    "\n",
    "            while idx < len(school_a):\n",
    "                a_tag_title = school_a[idx].get(\"title\")\n",
    "                a_tag_link = school_a[idx][\"href\"]\n",
    "\n",
    "                header_label_data_tuple = (i_header_text, i_label_text, i_data_text, a_tag_title, a_tag_link)\n",
    "                tuple_list.append(header_label_data_tuple)\n",
    "\n",
    "                idx += 1\n",
    "            \n",
    "            if len(school_a) == 0:\n",
    "                # print(i_data_text)\n",
    "                header_label_data_tuple = (i_header_text, i_label_text, i_data_text, np.nan, np.nan)\n",
    "                tuple_list.append(header_label_data_tuple)\n",
    "\n",
    "\n",
    "    info_box_df = pd.DataFrame.from_records(tuple_list, columns =['i_header', 'i_label', 'i_data', 'title', 'link'])\n",
    "\n",
    "    info_box_df[\"coach_name\"] = hc_df[\"coach\"][i]\n",
    "    info_box_df[\"id\"] = page_id\n",
    "\n",
    "    df_list.append(info_box_df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list)\n",
    "unq_before = list(df.i_header.unique())\n",
    "\n",
    "i_header_keep_list = [\"Career information\", \"Coaching career\", \"Coaching career (HC unless noted)\",\\\n",
    "                  \"Playing career\", \"Biographical details\", \"Administrative career (AD unless noted)\",\\\n",
    "                    \"Personal information\", \"Baseball\", \"Football\", \"Basketball\"]\n",
    "\n",
    "df_filt = df[df.i_header.isin(i_header_keep_list)]\n",
    "df_filt = df_filt[~((df_filt.i_header == \"Personal information\") & (df_filt.i_label != \"Born:\"))]\n",
    "\n",
    "unq_after = list(df_filt.i_header.unique())\n",
    "\n",
    "temp3 = [x for x in unq_before if x not in set(unq_after)]\n",
    "\n",
    "# print(\"Unique i_header: \\n\",unq_after)\n",
    "# print(\"Diff: \\n\",temp3)\n",
    "\n",
    "# print(df_filt.head())\n",
    "df_filt.to_csv('data/coach_details.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_sunbiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e16651120bc2828509cf0f9ed4e311eb58fe28d51ced9e067f144123d1b5e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
